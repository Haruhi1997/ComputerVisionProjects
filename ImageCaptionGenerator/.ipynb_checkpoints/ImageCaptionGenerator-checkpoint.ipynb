{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "colab_type": "code",
    "id": "U-urCDe1mhQ9",
    "outputId": "60d44fe5-7bb4-4cb3-a043-9cf0ab9f77da"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /content/gdrive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "oQre1qryCVE3",
    "outputId": "24fd3e60-4f34-4483-e037-abdf2b578d89"
   },
   "outputs": [],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 89,
     "resources": {
      "http://localhost:8080/nbextensions/google.colab/files.js": {
       "data": "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",
       "headers": [
        [
         "content-type",
         "application/javascript"
        ]
       ],
       "ok": true,
       "status": 200,
       "status_text": ""
      }
     }
    },
    "colab_type": "code",
    "id": "ib0-1G7NGUjn",
    "outputId": "d3dbfef7-5903-4b0a-8ca0-e1c749c557c5"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "     <input type=\"file\" id=\"files-e0413b32-e2d1-4bb0-866e-9010031d9e85\" name=\"files[]\" multiple disabled\n",
       "        style=\"border:none\" />\n",
       "     <output id=\"result-e0413b32-e2d1-4bb0-866e-9010031d9e85\">\n",
       "      Upload widget is only available when the cell has been executed in the\n",
       "      current browser session. Please rerun this cell to enable.\n",
       "      </output>\n",
       "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving kaggle.json to kaggle.json\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'kaggle.json': b'{\"username\":\"imnancy\",\"key\":\"7bc10107ac376be7f29e443c920462f7\"}'}"
      ]
     },
     "execution_count": 6,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from google.colab import files\n",
    "files.upload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 109,
     "resources": {
      "http://localhost:8080/nbextensions/google.colab/files.js": {
       "data": "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",
       "headers": [
        [
         "content-type",
         "application/javascript"
        ]
       ],
       "ok": true,
       "status": 200,
       "status_text": ""
      }
     }
    },
    "colab_type": "code",
    "id": "9TYJ6324KPqH",
    "outputId": "55788dd6-cc5a-45ac-d3d3-7f02192eda62"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "     <input type=\"file\" id=\"files-9c01de28-62e3-4ce7-9a5e-6c18f41cd6a4\" name=\"files[]\" multiple disabled\n",
       "        style=\"border:none\" />\n",
       "     <output id=\"result-9c01de28-62e3-4ce7-9a5e-6c18f41cd6a4\">\n",
       "      Upload widget is only available when the cell has been executed in the\n",
       "      current browser session. Please rerun this cell to enable.\n",
       "      </output>\n",
       "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving test.py to test.py\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'test.py': b'# -*- coding: utf-8 -*-\\n\"\"\"Untitled1.ipynb\\n\\nAutomatically generated by Colaboratory.\\n\\nOriginal file is located at\\n    https://colab.research.google.com/drive/1kCPFdt4Eps7a3PWQk9WWqktkQ3-XxooD\\n\"\"\"\\n\\n#Load model\\n#generate predictions\\nimport numpy as np\\nfrom PIL import Image\\nimport matplotlib.pyplot as plt\\nimport argparse\\nap = argparse.ArgumentParser()\\nap.add_argument(\\'-i\\', \\'--image\\', required=True, help=\"Image Path\")\\nargs = vars(ap.parse_args())\\nimg_path = args[\\'image\\']\\ndef extract_features(filename, model):\\n        try:\\n            image = Image.open(filename)\\n        except:\\n            print(\"ERROR: Couldn\\'t open image! Make sure the image path and extension is correct\")\\n        image = image.resize((299,299))\\n        image = np.array(image)\\n        # for images that has 4 channels, we convert them into 3 channels\\n        if image.shape[2] == 4: \\n            image = image[..., :3]\\n        image = np.expand_dims(image, axis=0)\\n        image = image/127.5\\n        image = image - 1.0\\n        feature = model.predict(image)\\n        return feature\\ndef word_for_id(integer, tokenizer):\\n  for word, index in tokenizer.word_index.items():\\n     if index == integer:\\n         return word\\n  return None\\ndef generate_desc(model, tokenizer, photo, max_length):\\n    in_text = \\'start\\'\\n    for i in range(max_length):\\n        sequence = tokenizer.texts_to_sequences([in_text])[0]\\n        sequence = pad_sequences([sequence], maxlen=max_length)\\n        pred = model.predict([photo,sequence], verbose=0)\\n        pred = np.argmax(pred)\\n        word = word_for_id(pred, tokenizer)\\n        if word is None:\\n            break\\n        in_text += \\' \\' + word\\n        if word == \\'end\\':\\n            break\\n    return in_text\\n#path = \\'Flicker8k_Dataset/111537222_07e56d5a30.jpg\\'\\nmax_length = 32\\ntokenizer = load(open(\"tokenizer.p\",\"rb\"))\\nmodel = load_model(\\'models/model_9.h5\\')\\nxception_model = Xception(include_top=False, pooling=\"avg\")\\nphoto = extract_features(img_path, xception_model)\\nimg = Image.open(img_path)\\ndescription = generate_desc(model, tokenizer, photo, max_length)\\nprint(\"\\\\n\\\\n\")\\nprint(description)\\nplt.imshow(img)\\n\\n'}"
      ]
     },
     "execution_count": 93,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files.upload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "kGWE08swGrdb",
    "outputId": "9efac015-383e-4636-ba25-610afefbf9e0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rw-r--r-- 1 root root 63 Jul 20 07:58 kaggle.json\n"
     ]
    }
   ],
   "source": [
    "!pip install -q kaggle\n",
    "!mkdir -p ~/.kaggle\n",
    "!cp kaggle.json ~/.kaggle/\n",
    "!chmod 600 ~/.kaggle/kaggle.json\n",
    "#cd /root/.kaggle\n",
    "!ls -lha kaggle.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "w2SIwZCaIxsg",
    "outputId": "067afab5-95b5-41ad-8dd7-04ec8376f03f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading flickr8k.zip to /content\n",
      " 99% 2.11G/2.13G [00:32<00:00, 69.5MB/s]\n",
      "100% 2.13G/2.13G [00:32<00:00, 69.9MB/s]\n"
     ]
    }
   ],
   "source": [
    "! kaggle datasets download -d 'shadabhussain/flickr8k'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 88
    },
    "colab_type": "code",
    "id": "Y_zJwWPwJrKp",
    "outputId": "aa25e5b6-a8bc-4fb7-956c-3f2d61ecbef2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shadabhussain/flickr8k                             Flickr8K                                            2GB  2019-03-24 17:53:27           4197  \n",
      "srbhshinde/flickr8k-sau                            flickr8k_sau                                        2GB  2019-02-18 05:23:24            616  \n",
      "adityajn105/flickr8k                               Flickr 8k Dataset                                   1GB  2020-04-27 07:27:19            281  \n"
     ]
    }
   ],
   "source": [
    "! kaggle datasets list -s flickr | grep 8k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "iE-dO8uRJyM5",
    "outputId": "9e67b476-c775-4fb7-beea-b304c698ce35"
   },
   "outputs": [],
   "source": [
    "#!unzip flickr-image-dataset.zip\n",
    "#!ls\n",
    "! unzip flickr8k.zip\n",
    "! ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 66,
     "referenced_widgets": [
      "0296430fd2224a258ae7e550687aaf1c",
      "dcfb63bf42274a969f583712bb1d409d",
      "db9fc082740245d6930938fd096837a4",
      "01548bdd5b884132815ed2263a312f23",
      "cd41028aa9f74ef081b0de5f62d7f69a",
      "c86b7774dfb74db3a55e65fd6617e766",
      "5e234d1f296a447693a7f7cfdf938192",
      "1deb5a9efc0343dcaca96b3275470d46"
     ]
    },
    "colab_type": "code",
    "id": "vjA7jts7nAF_",
    "outputId": "775b144e-0b0b-4022-90ee-8cdf6070d006"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0296430fd2224a258ae7e550687aaf1c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import string\n",
    "import numpy as np\n",
    "#PIL=pillow lib for image processing and loading or creating\n",
    "from PIL import Image\n",
    "import os\n",
    "#Pickle=py lib to seerialise/deserialize py data structures for easy loading.\n",
    "from pickle import dump, load\n",
    "import numpy as np\n",
    "from keras.applications.xception import Xception, preprocess_input\n",
    "from keras.preprocessing.image import load_img, img_to_array\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import to_categorical\n",
    "from keras.layers.merge import add\n",
    "from keras.models import Model, load_model\n",
    "from keras.layers import Input, Dense, LSTM, Embedding, Dropout\n",
    "# small library for seeing the progress of loops.\n",
    "from tqdm.notebook import tqdm as tqdm\n",
    "tqdm().pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kruAECZRyXnB"
   },
   "outputs": [],
   "source": [
    "def load_doc(filename):\n",
    "  f = open(filename,'r')\n",
    "  content= f.readlines()\n",
    "  f.close()\n",
    "  return content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "iABU37R9Of-D",
    "outputId": "bb759a7a-972e-46df-fd92-9f3bdad21092"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#Each image has 5 captions. So creating a dict with key=imgname and\n",
    "# val = all 5 image captions list\n",
    "def all_img_captions(filename):\n",
    "  lines=load_doc(filename)\n",
    "  imagedesc={}\n",
    "  for line in lines:\n",
    "    words = line.split('\\t')\n",
    "    imgphrase = words[0]\n",
    "    imgname = imgphrase.split('#')[0]\n",
    "    if imgname in imagedesc:\n",
    "      imagedesc[imgname].append(words[1])\n",
    "    else:\n",
    "      imagedesc[imgname]=[words[1]]\n",
    "  return imagedesc\n",
    "#desc = all_img_captions(filename)\n",
    "#cleaning_text(allimg_captions(filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zp-WkTYSyZ7Q"
   },
   "outputs": [],
   "source": [
    "def cleaning_text(descriptions):\n",
    "  table = str.maketrans('','',string.punctuation)\n",
    "  for img,caps in descriptions.items():\n",
    "    for i,img_caption in enumerate(caps):\n",
    "      #Iterating through each of the 5 captions for an image\n",
    "      img_caption.replace(\"-\",\" \")\n",
    "      des = img_caption.split()\n",
    "      #converting to lower case\n",
    "      des = [word.lower() for word in des]\n",
    "      #Removing punctuation\n",
    "      des = [word.translate(table) for word in des]\n",
    "      #Remove hanging 's and a by checking if word length is greater than 1\n",
    "      des = [word for word in des if len(word)>1]\n",
    "      #Remove tokens with numbers in them\n",
    "      des = [word for word in des if (word.isalpha())]\n",
    "\n",
    "      img_caption = ' '.join(des)\n",
    "      descriptions[img][i]=img_caption\n",
    "  return descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UjpWWHlmVThd"
   },
   "outputs": [],
   "source": [
    "def text_vocabulary(cleanedList):\n",
    "  vocab=set()\n",
    "  for key in cleanedList.keys():\n",
    "    [vocab.update(d.split()) for d in cleanedList[key]]\n",
    "  return vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "irR8sBjeit-p"
   },
   "outputs": [],
   "source": [
    "def save_descriptions(descriptions, filename):\n",
    "  lines = list()\n",
    "  for key,desc_list in descriptions.items():\n",
    "    for desc in desc_list:\n",
    "      lines.append(key + '\\t'+desc)\n",
    "  data = \"\\n\".join(lines)\n",
    "  f = open(filename,'w')\n",
    "  f.write(data)\n",
    "  f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "L_PJzfDHi_1W"
   },
   "outputs": [],
   "source": [
    "dataset_text = '/content/flickr_data/Flickr_Data/Flickr_TextData/Flickr8k.token.txt'\n",
    "descriptions = all_img_captions(dataset_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FhwIDRNlbhRF"
   },
   "source": [
    "Flickr8k.token.txt contains imgnames< Tab >description sentence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "zXiAj_WZpE-P",
    "outputId": "6ba5bf58-75b0-4fd3-ec93-598ec68efe21"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len of descriptions:  8092\n"
     ]
    }
   ],
   "source": [
    "print(\"len of descriptions: \",len(descriptions))\n",
    "clean_descriptions = cleaning_text(descriptions)\n",
    "vocabulary = text_vocabulary(clean_descriptions)\n",
    "save_descriptions(clean_descriptions,'descriptions.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 100,
     "referenced_widgets": [
      "287022c2589447a7b5e3596c206e1543",
      "780d89f11c6a4aafbe7e7ee8a200c2df",
      "f88ae578796847c5b405eb7e97caf336",
      "2fe148cf9d754f0380ceecfd74c0c749",
      "6eefe4533fba4f2bb18af1f1c9ae7279",
      "9a9d6f798db146ceacb43c6ebe55a936",
      "ee5e4ba62e4840039a885bf2e89493b6",
      "ad14acec3317488797944eabcc18c304"
     ]
    },
    "colab_type": "code",
    "id": "i6U-8y2vpOBc",
    "outputId": "023b498d-7222-49fb-f7a8-07d5c353ae07"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.4/xception_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "83689472/83683744 [==============================] - 4s 0us/step\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "287022c2589447a7b5e3596c206e1543",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=8091.0), HTML(value='')))"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def extract_features(directory):\n",
    "  #Removing last clasification layer to get 2048 feature vector\n",
    "  model = Xception(include_top=False,pooling='avg')\n",
    "  features = {}\n",
    "  cnt=0\n",
    "  for img in tqdm(os.listdir(directory)):\n",
    "    cnt+=1\n",
    "    filename = directory+\"/\"+img\n",
    "    #print(filename)\n",
    "    image = Image.open(filename)\n",
    "    #Resizing the image since Xception neural net accepts inputs of size (299,299,3)\n",
    "    image = image.resize((299,299))\n",
    "    image = np.expand_dims(image,axis=0)\n",
    "    #Converting to graysale??\n",
    "    image = image/127.5\n",
    "    image = image-1.0\n",
    "    #Process of standardising the data by subtracting std, dividing by mean\n",
    "    #Didnt understand how we gotthe nums exactly \n",
    "\n",
    "    feature = model.predict(image)\n",
    "    #print(feature)\n",
    "    features[img] = feature\n",
    "    #print('Done for %d imgs' %(cnt))\n",
    "  return features\n",
    "dataset_images='/content/flickr_data/Flickr_Data/Images'\n",
    "features = extract_features(dataset_images)\n",
    "#Dumping all the features into pickled format via dump command in pickle module\n",
    "#Dumping to features.p via write binary mode \n",
    "#\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "id": "pu1HbCRi8HgX",
    "outputId": "6cfe1177-2e30-44fe-92fb-4dd8dddc8cfa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3,) [1 2 3]\n",
      "(1, 3) [[1 2 3]]\n",
      "(3, 1) [[1]\n",
      " [2]\n",
      " [3]]\n"
     ]
    }
   ],
   "source": [
    "a=np.array([1,2,3])\n",
    "print(a.shape,a)\n",
    "b=np.expand_dims(a,axis=0)\n",
    "print(b.shape,b)\n",
    "c=np.expand_dims(a,axis=1)\n",
    "print(c.shape,c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XWE7Olp89Oen"
   },
   "outputs": [],
   "source": [
    "dump(features, open('features.p','wb'))\n",
    "features = load(open('features.p','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "E5ak2PRYEFrh",
    "outputId": "8183449f-37df-4634-9cf0-c860e0d740fc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8091"
      ]
     },
     "execution_count": 21,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#features is a dict where key= img name value=feature vector obtained from Xception model trained on imagenet\n",
    "len(features.items())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Pa51QOPqbCog"
   },
   "source": [
    "**Loading dataset for training**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Qy8RWtm_cTj8"
   },
   "source": [
    " Flickr_8k.trainImages.txt-/flickr_data/Flickr_TextData/Flicke_8k.trainImages.txt\n",
    " \n",
    " This file contains the list of 6000 images used for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9Snq3yjsWrmN"
   },
   "outputs": [],
   "source": [
    "# Loading image names from text file in a string and return list of image names\n",
    "def load_photos(filename):\n",
    "  images =load_doc(filename)\n",
    "  res=[]\n",
    "  for img in images:\n",
    "    res.append(img.strip())\n",
    "  return res\n",
    "train_images = load_photos('flickr_data/Flickr_Data/Flickr_TextData/Flickr_8k.trainImages.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "rxijBGWfEkce",
    "outputId": "32b95bed-6e13-4600-8a6f-49c82508fee0"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic": {
       "type": "string"
      },
      "text/plain": [
       "'2513260012_03d33305cf.jpg'"
      ]
     },
     "execution_count": 23,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 6000 images are classified as training images in\n",
    "train_images[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WvqJqR8gc9oj"
   },
   "outputs": [],
   "source": [
    "def load_clean_descriptions(filename,photos):\n",
    "  file = load_doc(filename)\n",
    "  descriptions = {}\n",
    "  for line in file:\n",
    "    words=line.split()\n",
    "    if len(words)<2:\n",
    "      continue\n",
    "\n",
    "    img,img_caption = words[0],words[1:]\n",
    "    if img in photos:\n",
    "      if img not in descriptions:\n",
    "        descriptions[img] = []\n",
    "        #For LSTM to easily identify starting and ending of the \n",
    "      desc = '<start> '+\" \".join(img_caption)+' <end>'\n",
    "      descriptions[img].append(desc)\n",
    "\n",
    "  return descriptions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9WYiQvYWfvi9"
   },
   "outputs": [],
   "source": [
    "def load_features(photos):\n",
    "  #We need to extract the features which er previously stored in features.p \n",
    "  all_features = load(open('features.p','rb'))\n",
    "  #Taking only features for photos in our fxn argument\n",
    "  features = {k:all_features[k] for k in photos}\n",
    "  return features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nMcNZNuTfv2y"
   },
   "outputs": [],
   "source": [
    "textDatapath = '/content/flickr_data/Flickr_Data/Flickr_TextData/'\n",
    "trainImgTextPath = textDatapath+'Flickr_8k.trainImages.txt'\n",
    "train_imgs = load_photos(trainImgTextPath)\n",
    "train_descriptions = load_clean_descriptions('descriptions.txt',train_imgs)\n",
    "train_features = load_features(train_imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "Xpu6wuhXZYAB",
    "outputId": "46d19db6-7ba9-4b4f-874a-112daf21f0c0"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic": {
       "type": "string"
      },
      "text/plain": [
       "'<start> child in pink dress is climbing up set of stairs in an entry way <end>'"
      ]
     },
     "execution_count": 27,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_descriptions['1000268201_693b08cb0e.jpg'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_H-Mp74vHuWP"
   },
   "source": [
    "**Tokenizing vocab**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tQMhAVOrHch2"
   },
   "outputs": [],
   "source": [
    "def dict_to_list(descriptions):\n",
    "  descList = []\n",
    "  for key in descriptions.keys():\n",
    "    [descList.append(d) for d in descriptions[key]]\n",
    "  return descList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "P9B5nt0NQxkn"
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "\n",
    "def create_tokenizer(descriptions):\n",
    "  desc_list = dict_to_list(descriptions)\n",
    "  tokenizer = Tokenizer()\n",
    "  #fit_on_texts puts the most frequent word as the first element in the list\n",
    "  tokenizer.fit_on_texts(desc_list)\n",
    "  return tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "UD5LEa9BSt6W",
    "outputId": "e6a023f5-6c73-4ae8-ed3a-f55b6f3f3976"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7577"
      ]
     },
     "execution_count": 30,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = create_tokenizer(train_descriptions)\n",
    "#Dumping words according to their frequency in tokenizer.p\n",
    "dump(tokenizer,open('tokenizer.p','wb'))\n",
    "vocab_size = len(tokenizer.word_index)+1 #Why +1?\n",
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "Qm4-vx1XT-GZ",
    "outputId": "d52d832c-fe2f-4e2f-de31-27421a55eb21"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7576"
      ]
     },
     "execution_count": 47,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Gives word:freq count\n",
    "tokenizer.word_index\n",
    "len(tokenizer.word_index)\n",
    "#Means there are 7576 unique words in descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "ZjQ1_uAEb8tu",
    "outputId": "92e0f80e-bcdd-4499-fd15-a66de0ac2577"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 31,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Calculating max length of descriptions\n",
    "def max_length(descriptions):\n",
    "  desc_list = dict_to_list(descriptions)\n",
    "  return max(len(d.split()) for d in desc_list)\n",
    "\n",
    "maxlen = max_length(descriptions)\n",
    "maxlen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "yimHANw1NlK-",
    "outputId": "b7e2a5ea-d722-41ed-8753-39ac0b972c0c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 2048)"
      ]
     },
     "execution_count": 41,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features['1000268201_693b08cb0e.jpg'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "w4YqUWxpQSdH",
    "outputId": "70a3afb8-4289-4933-fd10-b3c1d7612739"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2048,)"
      ]
     },
     "execution_count": 42,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features['1000268201_693b08cb0e.jpg'][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "WeJv2mknQcQg",
    "outputId": "04ee3922-fcca-46b0-b92a-bd9253a5a8f5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8092"
      ]
     },
     "execution_count": 43,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(descriptions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "u4yotI5EQhwC"
   },
   "outputs": [],
   "source": [
    "#imgname:[list of 5 descriptions]\n",
    "a=descriptions['2076428547_738e0a132f.jpg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "QZG-iHTmQ0xU",
    "outputId": "f23ec59c-8b74-494f-9c03-6afaa889edf7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "backpacker standing near water at dusk\n",
      "[1909, 38, 65, 23, 21, 1100]\n",
      "[1909] 38\n",
      "[   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0 1909]\n",
      "(32,)\n",
      "[0. 0. 0. ... 0. 0. 0.]\n",
      "(7577,)\n",
      "======================\n",
      "[1909, 38] 65\n",
      "[   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0 1909   38]\n",
      "(32,)\n",
      "[0. 0. 0. ... 0. 0. 0.]\n",
      "(7577,)\n",
      "======================\n",
      "[1909, 38, 65] 23\n",
      "[   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0 1909   38   65]\n",
      "(32,)\n",
      "[0. 0. 0. ... 0. 0. 0.]\n",
      "(7577,)\n",
      "======================\n",
      "[1909, 38, 65, 23] 21\n",
      "[   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      " 1909   38   65   23]\n",
      "(32,)\n",
      "[0. 0. 0. ... 0. 0. 0.]\n",
      "(7577,)\n",
      "======================\n",
      "[1909, 38, 65, 23, 21] 1100\n",
      "[   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0 1909\n",
      "   38   65   23   21]\n",
      "(32,)\n",
      "[0. 0. 0. ... 0. 0. 0.]\n",
      "(7577,)\n",
      "======================\n",
      "hiker is shadowed by the time of day near an open and treelined body of water\n",
      "[453, 6, 3049, 56, 4, 1263, 11, 360, 65, 27, 244, 7, 2374, 258, 11, 23]\n",
      "[453] 6\n",
      "[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0 453]\n",
      "(32,)\n",
      "[0. 0. 0. ... 0. 0. 0.]\n",
      "(7577,)\n",
      "======================\n",
      "[453, 6] 3049\n",
      "[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0 453   6]\n",
      "(32,)\n",
      "[0. 0. 0. ... 0. 0. 0.]\n",
      "(7577,)\n",
      "======================\n",
      "[453, 6, 3049] 56\n",
      "[   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0  453    6 3049]\n",
      "(32,)\n",
      "[0. 0. 0. ... 0. 0. 0.]\n",
      "(7577,)\n",
      "======================\n",
      "[453, 6, 3049, 56] 4\n",
      "[   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "  453    6 3049   56]\n",
      "(32,)\n",
      "[0. 0. 0. ... 0. 0. 0.]\n",
      "(7577,)\n",
      "======================\n",
      "[453, 6, 3049, 56, 4] 1263\n",
      "[   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0  453\n",
      "    6 3049   56    4]\n",
      "(32,)\n",
      "[0. 0. 0. ... 0. 0. 0.]\n",
      "(7577,)\n",
      "======================\n",
      "[453, 6, 3049, 56, 4, 1263] 11\n",
      "[   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0  453    6\n",
      " 3049   56    4 1263]\n",
      "(32,)\n",
      "[0. 0. 0. ... 0. 0. 0.]\n",
      "(7577,)\n",
      "======================\n",
      "[453, 6, 3049, 56, 4, 1263, 11] 360\n",
      "[   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0  453    6 3049\n",
      "   56    4 1263   11]\n",
      "(32,)\n",
      "[0. 0. 0. ... 0. 0. 0.]\n",
      "(7577,)\n",
      "======================\n",
      "[453, 6, 3049, 56, 4, 1263, 11, 360] 65\n",
      "[   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0  453    6 3049   56\n",
      "    4 1263   11  360]\n",
      "(32,)\n",
      "[0. 0. 0. ... 0. 0. 0.]\n",
      "(7577,)\n",
      "======================\n",
      "[453, 6, 3049, 56, 4, 1263, 11, 360, 65] 27\n",
      "[   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0  453    6 3049   56    4\n",
      " 1263   11  360   65]\n",
      "(32,)\n",
      "[0. 0. 0. ... 0. 0. 0.]\n",
      "(7577,)\n",
      "======================\n",
      "[453, 6, 3049, 56, 4, 1263, 11, 360, 65, 27] 244\n",
      "[   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0  453    6 3049   56    4 1263\n",
      "   11  360   65   27]\n",
      "(32,)\n",
      "[0. 0. 0. ... 0. 0. 0.]\n",
      "(7577,)\n",
      "======================\n",
      "[453, 6, 3049, 56, 4, 1263, 11, 360, 65, 27, 244] 7\n",
      "[   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0  453    6 3049   56    4 1263   11\n",
      "  360   65   27  244]\n",
      "(32,)\n",
      "[0. 0. 0. ... 0. 0. 0.]\n",
      "(7577,)\n",
      "======================\n",
      "[453, 6, 3049, 56, 4, 1263, 11, 360, 65, 27, 244, 7] 2374\n",
      "[   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0  453    6 3049   56    4 1263   11  360\n",
      "   65   27  244    7]\n",
      "(32,)\n",
      "[0. 0. 0. ... 0. 0. 0.]\n",
      "(7577,)\n",
      "======================\n",
      "[453, 6, 3049, 56, 4, 1263, 11, 360, 65, 27, 244, 7, 2374] 258\n",
      "[   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0  453    6 3049   56    4 1263   11  360   65\n",
      "   27  244    7 2374]\n",
      "(32,)\n",
      "[0. 0. 0. ... 0. 0. 0.]\n",
      "(7577,)\n",
      "======================\n",
      "[453, 6, 3049, 56, 4, 1263, 11, 360, 65, 27, 244, 7, 2374, 258] 11\n",
      "[   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0  453    6 3049   56    4 1263   11  360   65   27\n",
      "  244    7 2374  258]\n",
      "(32,)\n",
      "[0. 0. 0. ... 0. 0. 0.]\n",
      "(7577,)\n",
      "======================\n",
      "[453, 6, 3049, 56, 4, 1263, 11, 360, 65, 27, 244, 7, 2374, 258, 11] 23\n",
      "[   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0  453    6 3049   56    4 1263   11  360   65   27  244\n",
      "    7 2374  258   11]\n",
      "(32,)\n",
      "[0. 0. 0. ... 0. 0. 0.]\n",
      "(7577,)\n",
      "======================\n",
      "hiker profile against blue sky and mountain range\n",
      "[453, 2659, 242, 29, 327, 7, 111, 981]\n",
      "[453] 2659\n",
      "[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0 453]\n",
      "(32,)\n",
      "[0. 0. 0. ... 0. 0. 0.]\n",
      "(7577,)\n",
      "======================\n",
      "[453, 2659] 242\n",
      "[   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0  453 2659]\n",
      "(32,)\n",
      "[0. 0. 0. ... 0. 0. 0.]\n",
      "(7577,)\n",
      "======================\n",
      "[453, 2659, 242] 29\n",
      "[   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0  453 2659  242]\n",
      "(32,)\n",
      "[0. 0. 0. ... 0. 0. 0.]\n",
      "(7577,)\n",
      "======================\n",
      "[453, 2659, 242, 29] 327\n",
      "[   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "  453 2659  242   29]\n",
      "(32,)\n",
      "[0. 0. 0. ... 0. 0. 0.]\n",
      "(7577,)\n",
      "======================\n",
      "[453, 2659, 242, 29, 327] 7\n",
      "[   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0  453\n",
      " 2659  242   29  327]\n",
      "(32,)\n",
      "[0. 0. 0. ... 0. 0. 0.]\n",
      "(7577,)\n",
      "======================\n",
      "[453, 2659, 242, 29, 327, 7] 111\n",
      "[   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0  453 2659\n",
      "  242   29  327    7]\n",
      "(32,)\n",
      "[0. 0. 0. ... 0. 0. 0.]\n",
      "(7577,)\n",
      "======================\n",
      "[453, 2659, 242, 29, 327, 7, 111] 981\n",
      "[   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0  453 2659  242\n",
      "   29  327    7  111]\n",
      "(32,)\n",
      "[0. 0. 0. ... 0. 0. 0.]\n",
      "(7577,)\n",
      "======================\n",
      "hiker standing on the shore of lake\n",
      "[453, 38, 5, 4, 306, 11, 179]\n",
      "[453] 38\n",
      "[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0 453]\n",
      "(32,)\n",
      "[0. 0. 0. ... 0. 0. 0.]\n",
      "(7577,)\n",
      "======================\n",
      "[453, 38] 5\n",
      "[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0 453  38]\n",
      "(32,)\n",
      "[0. 0. 0. ... 0. 0. 0.]\n",
      "(7577,)\n",
      "======================\n",
      "[453, 38, 5] 4\n",
      "[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0 453  38   5]\n",
      "(32,)\n",
      "[0. 0. 0. ... 0. 0. 0.]\n",
      "(7577,)\n",
      "======================\n",
      "[453, 38, 5, 4] 306\n",
      "[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0 453  38   5   4]\n",
      "(32,)\n",
      "[0. 0. 0. ... 0. 0. 0.]\n",
      "(7577,)\n",
      "======================\n",
      "[453, 38, 5, 4, 306] 11\n",
      "[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0 453  38   5   4 306]\n",
      "(32,)\n",
      "[0. 0. 0. ... 0. 0. 0.]\n",
      "(7577,)\n",
      "======================\n",
      "[453, 38, 5, 4, 306, 11] 179\n",
      "[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0 453  38   5   4 306  11]\n",
      "(32,)\n",
      "[0. 0. 0. ... 0. 0. 0.]\n",
      "(7577,)\n",
      "======================\n",
      "man with hiking backpack on is standing in front of lake with forest in the background\n",
      "[10, 9, 520, 281, 5, 6, 38, 3, 48, 11, 179, 9, 278, 3, 4, 105]\n",
      "[10] 9\n",
      "[ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0 10]\n",
      "(32,)\n",
      "[0. 0. 0. ... 0. 0. 0.]\n",
      "(7577,)\n",
      "======================\n",
      "[10, 9] 520\n",
      "[ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0 10  9]\n",
      "(32,)\n",
      "[0. 0. 0. ... 0. 0. 0.]\n",
      "(7577,)\n",
      "======================\n",
      "[10, 9, 520] 281\n",
      "[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0  10   9 520]\n",
      "(32,)\n",
      "[0. 0. 0. ... 0. 0. 0.]\n",
      "(7577,)\n",
      "======================\n",
      "[10, 9, 520, 281] 5\n",
      "[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0  10   9 520 281]\n",
      "(32,)\n",
      "[0. 0. 0. ... 0. 0. 0.]\n",
      "(7577,)\n",
      "======================\n",
      "[10, 9, 520, 281, 5] 6\n",
      "[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0  10   9 520 281   5]\n",
      "(32,)\n",
      "[0. 0. 0. ... 0. 0. 0.]\n",
      "(7577,)\n",
      "======================\n",
      "[10, 9, 520, 281, 5, 6] 38\n",
      "[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0  10   9 520 281   5   6]\n",
      "(32,)\n",
      "[0. 0. 0. ... 0. 0. 0.]\n",
      "(7577,)\n",
      "======================\n",
      "[10, 9, 520, 281, 5, 6, 38] 3\n",
      "[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0  10   9 520 281   5   6  38]\n",
      "(32,)\n",
      "[0. 0. 0. ... 0. 0. 0.]\n",
      "(7577,)\n",
      "======================\n",
      "[10, 9, 520, 281, 5, 6, 38, 3] 48\n",
      "[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0  10   9 520 281   5   6  38   3]\n",
      "(32,)\n",
      "[0. 0. 0. ... 0. 0. 0.]\n",
      "(7577,)\n",
      "======================\n",
      "[10, 9, 520, 281, 5, 6, 38, 3, 48] 11\n",
      "[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0  10   9 520 281   5   6  38   3  48]\n",
      "(32,)\n",
      "[0. 0. 0. ... 0. 0. 0.]\n",
      "(7577,)\n",
      "======================\n",
      "[10, 9, 520, 281, 5, 6, 38, 3, 48, 11] 179\n",
      "[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0  10   9 520 281   5   6  38   3  48  11]\n",
      "(32,)\n",
      "[0. 0. 0. ... 0. 0. 0.]\n",
      "(7577,)\n",
      "======================\n",
      "[10, 9, 520, 281, 5, 6, 38, 3, 48, 11, 179] 9\n",
      "[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0  10   9 520 281   5   6  38   3  48  11 179]\n",
      "(32,)\n",
      "[0. 0. 0. ... 0. 0. 0.]\n",
      "(7577,)\n",
      "======================\n",
      "[10, 9, 520, 281, 5, 6, 38, 3, 48, 11, 179, 9] 278\n",
      "[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0  10   9 520 281   5   6  38   3  48  11 179   9]\n",
      "(32,)\n",
      "[0. 0. 0. ... 0. 0. 0.]\n",
      "(7577,)\n",
      "======================\n",
      "[10, 9, 520, 281, 5, 6, 38, 3, 48, 11, 179, 9, 278] 3\n",
      "[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0  10   9 520 281   5   6  38   3  48  11 179   9 278]\n",
      "(32,)\n",
      "[0. 0. 0. ... 0. 0. 0.]\n",
      "(7577,)\n",
      "======================\n",
      "[10, 9, 520, 281, 5, 6, 38, 3, 48, 11, 179, 9, 278, 3] 4\n",
      "[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "  10   9 520 281   5   6  38   3  48  11 179   9 278   3]\n",
      "(32,)\n",
      "[0. 0. 0. ... 0. 0. 0.]\n",
      "(7577,)\n",
      "======================\n",
      "[10, 9, 520, 281, 5, 6, 38, 3, 48, 11, 179, 9, 278, 3, 4] 105\n",
      "[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  10\n",
      "   9 520 281   5   6  38   3  48  11 179   9 278   3   4]\n",
      "(32,)\n",
      "[0. 0. 0. ... 0. 0. 0.]\n",
      "(7577,)\n",
      "======================\n"
     ]
    }
   ],
   "source": [
    "for k in a:\n",
    "  print(k)\n",
    "  se = tokenizer.texts_to_sequences([k])[0]\n",
    "  #print((tokenizer.texts_to_sequences([k])))\n",
    "  print(se)\n",
    "  for i in range(1,len(se)):\n",
    "    ins,ous = se[:i],se[i]\n",
    "    print(ins,ous)\n",
    "    #Converts to sparse matric where all other words have 0 except current word\n",
    "    ins = pad_sequences([ins],maxlen=maxlen)[0]\n",
    "    print(ins)\n",
    "    print(ins.shape)\n",
    "    ous = to_categorical([ous],num_classes=vocab_size)[0]\n",
    "    print(ous)\n",
    "    print(ous.shape)\n",
    "    print('======================')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "ibkaGjUeWJ0u",
    "outputId": "c7cca95b-d349-4814-d158-3b916b6b8486"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15, 2048) (15, 32) (15, 7577)\n"
     ]
    }
   ],
   "source": [
    "#Creating input output sequences from features dict(imgname:featuresvector), \n",
    "#descriptions dict(imgname:listof5descriptions) and tokenizerwhich is already trained on\n",
    "#descriptions and finally maxlen=max length of sentence in descriptions.\n",
    "\n",
    "def data_generator(descriptions,features,tokenizer,max_length):\n",
    "  while 1:\n",
    "    for key, description in descriptions.items():\n",
    "      imgname= key\n",
    "      #Extract feature vector for that image\n",
    "      featurevector = features[imgname][0]\n",
    "      ip_img,ip_sqnce,op_word = create_sequences(tokenizer,max_length,description,featurevector)\n",
    "      yield [[ip_img,ip_sqnce],op_word]\n",
    "def create_sequences(tokenizer, max_length, desc_list,featurevector):\n",
    "  X1, X2, y = list() ,list(), list()\n",
    "\n",
    "  for desc in desc_list:\n",
    "    #Encode the sequence\n",
    "    seq = tokenizer.texts_to_sequences([desc])[0]\n",
    "    #Above line returns assigned unqiue number to word while processing tokens before\n",
    "    #seq=[12 ....n numbers......] where n=num of words in a sentence\n",
    "    for i in range(1,len(seq)):\n",
    "      #We need to predict the next word given one input word.\n",
    "      #Hence splitting it to input output word pair\n",
    "      in_seq,out_seq = seq[:i],seq[i]\n",
    "      #Pad input sequence into a sparse matrix with length = maxlen\n",
    "      #max len is maxlen of any given description\n",
    "      in_seq = pad_sequences([in_seq],maxlen=max_length)[0]\n",
    "      out_seq = to_categorical([out_seq],num_classes=vocab_size)[0]\n",
    "\n",
    "      X1.append(featurevector)\n",
    "      X2.append(in_seq)\n",
    "      y.append(out_seq)\n",
    "\n",
    "    return np.array(X1),np.array(X2),np.array(y)\n",
    "\n",
    "[a,b],c = next(data_generator(train_descriptions, features, tokenizer,maxlen))\n",
    "print(a.shape,b.shape, c.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "g879UK2fq2in"
   },
   "outputs": [],
   "source": [
    "from keras.utils import plot_model\n",
    "#Defininf the model\n",
    "def define_model(vocab_size,maxlendescriptions):\n",
    "  #Image ips \n",
    "  i1 = Input(shape=(2048,))\n",
    "  fe1 = Dropout(0.5)(i1)\n",
    "  fe2 = Dense(256, activation='relu')(fe1)\n",
    "  print(\"D1\")\n",
    "  #Vocab inputs\n",
    "  i2 = Input(shape=(maxlendescriptions,))\n",
    "  print(\"D!!\")\n",
    "  se1 = Embedding(vocab_size,256,mask_zero=True)(i2)\n",
    "  print(\"D!!1\")\n",
    "  se2 = Dropout(0.5)(se1)\n",
    "  print(\"D!!2\")\n",
    "  #LSTM\n",
    "  se3 = LSTM(256)(se2)\n",
    "  print(\"D2\")\n",
    "  #Merge both models\n",
    "  decoder1 = add([fe2,se3])\n",
    "  decoder2 = Dense(256, activation='relu')(decoder1)\n",
    "  outputs = Dense(vocab_size,activation='softmax')(decoder2)\n",
    "  print(\"D3\")\n",
    "  model = Model(inputs=[i1,i2],outputs=outputs)\n",
    "  model.compile(loss='categorical_crossentropy',optimizer='adam')\n",
    "  print(\"D4\")\n",
    "  print(model.summary())\n",
    "  plot_model(model, to_file='model.png',show_shapes=True)\n",
    "\n",
    "  return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "bPUlfhewtPPS",
    "outputId": "f60d60f6-7842-4342-9b38-ace90e0249dc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6000\n",
      "6000 6000 7577 32\n"
     ]
    }
   ],
   "source": [
    "#Training model in batches on 6000 images \n",
    "print(len(train_imgs))\n",
    "print(len(train_descriptions),len(train_features),vocab_size,maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 646
    },
    "colab_type": "code",
    "id": "YvG_53WS5528",
    "outputId": "0c87bf22-1f0c-459e-9a02-dc50645da230"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D1\n",
      "D!!\n",
      "D!!1\n",
      "D!!2\n",
      "D2\n",
      "D3\n",
      "D4\n",
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_12 (InputLayer)           (None, 32)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_11 (InputLayer)           (None, 2048)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_2 (Embedding)         (None, 32, 256)      1939712     input_12[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)             (None, 2048)         0           input_11[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)             (None, 32, 256)      0           embedding_2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 256)          524544      dropout_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lstm_2 (LSTM)                   (None, 256)          525312      dropout_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_14 (Add)                    (None, 256)          0           dense_7[0][0]                    \n",
      "                                                                 lstm_2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 256)          65792       add_14[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_9 (Dense)                 (None, 7577)         1947289     dense_8[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 5,002,649\n",
      "Trainable params: 5,002,649\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = define_model(vocab_size,maxlen)\n",
    "epochs=10\n",
    "steps=len(train_descriptions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 357
    },
    "colab_type": "code",
    "id": "Mgkvc0PT6E_n",
    "outputId": "66d6f428-cfa7-481f-d311-cd023378bca5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "6000/6000 [==============================] - 487s 81ms/step - loss: 3.2114\n",
      "Epoch 1/1\n",
      "6000/6000 [==============================] - 486s 81ms/step - loss: 3.0985\n",
      "Epoch 1/1\n",
      "6000/6000 [==============================] - 488s 81ms/step - loss: 2.9997\n",
      "Epoch 1/1\n",
      "6000/6000 [==============================] - 495s 83ms/step - loss: 2.9171\n",
      "Epoch 1/1\n",
      "6000/6000 [==============================] - 500s 83ms/step - loss: 2.8483\n",
      "Epoch 1/1\n",
      "6000/6000 [==============================] - 492s 82ms/step - loss: 2.7989\n",
      "Epoch 1/1\n",
      "6000/6000 [==============================] - 493s 82ms/step - loss: 2.7466\n",
      "Epoch 1/1\n",
      "6000/6000 [==============================] - 487s 81ms/step - loss: 2.6989\n",
      "Epoch 1/1\n",
      "6000/6000 [==============================] - 502s 84ms/step - loss: 2.6648\n",
      "Epoch 1/1\n",
      "6000/6000 [==============================] - 512s 85ms/step - loss: 2.6161\n"
     ]
    }
   ],
   "source": [
    "os.mkdir(\"models\")\n",
    "for i in range(epochs):\n",
    "  generator= data_generator(train_descriptions,train_features, tokenizer,maxlen)\n",
    "  model.fit_generator(generator,epochs=1, steps_per_epoch=steps, verbose=1)\n",
    "  model.save(\"models/model_\"+str(i)+\".h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 955
    },
    "colab_type": "code",
    "id": "VrBf_CzO6Gxq",
    "outputId": "240776ea-81bf-4e05-d5d8-3deb2a9bd4fb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "2020-07-20 13:57:49.521533: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
      "2020-07-20 13:57:51.005497: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
      "2020-07-20 13:57:51.010397: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2020-07-20 13:57:51.010900: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 0 with properties: \n",
      "pciBusID: 0000:00:04.0 name: Tesla T4 computeCapability: 7.5\n",
      "coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.73GiB deviceMemoryBandwidth: 298.08GiB/s\n",
      "2020-07-20 13:57:51.010943: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
      "2020-07-20 13:57:51.012700: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
      "2020-07-20 13:57:51.014364: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
      "2020-07-20 13:57:51.014703: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
      "2020-07-20 13:57:51.016536: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
      "2020-07-20 13:57:51.017655: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
      "2020-07-20 13:57:51.021212: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
      "2020-07-20 13:57:51.021324: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2020-07-20 13:57:51.021757: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2020-07-20 13:57:51.022162: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1703] Adding visible gpu devices: 0\n",
      "2020-07-20 13:57:51.022373: I tensorflow/core/platform/cpu_feature_guard.cc:143] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX512F\n",
      "2020-07-20 13:57:51.027831: I tensorflow/core/platform/profile_utils/cpu_utils.cc:102] CPU Frequency: 2000125000 Hz\n",
      "2020-07-20 13:57:51.028082: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x231ed80 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-07-20 13:57:51.028118: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "2020-07-20 13:57:51.121829: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2020-07-20 13:57:51.122448: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x231ef40 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2020-07-20 13:57:51.122493: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\n",
      "2020-07-20 13:57:51.122716: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2020-07-20 13:57:51.123179: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 0 with properties: \n",
      "pciBusID: 0000:00:04.0 name: Tesla T4 computeCapability: 7.5\n",
      "coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.73GiB deviceMemoryBandwidth: 298.08GiB/s\n",
      "2020-07-20 13:57:51.123233: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
      "2020-07-20 13:57:51.123269: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
      "2020-07-20 13:57:51.123296: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
      "2020-07-20 13:57:51.123321: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
      "2020-07-20 13:57:51.123347: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
      "2020-07-20 13:57:51.123373: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
      "2020-07-20 13:57:51.123398: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
      "2020-07-20 13:57:51.123479: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2020-07-20 13:57:51.123967: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2020-07-20 13:57:51.124358: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1703] Adding visible gpu devices: 0\n",
      "2020-07-20 13:57:51.124412: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
      "2020-07-20 13:57:51.642314: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2020-07-20 13:57:51.642373: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1108]      0 \n",
      "2020-07-20 13:57:51.642385: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1121] 0:   N \n",
      "2020-07-20 13:57:51.642585: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2020-07-20 13:57:51.643075: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2020-07-20 13:57:51.643448: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
      "2020-07-20 13:57:51.643488: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1247] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 7394 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/indexed_slices.py:434: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "2020-07-20 13:57:56.441214: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
      "2020-07-20 13:57:58.118336: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
      "\n",
      "\n",
      "\n",
      "start boy in pink shirt is playing on the sidewalk end\n"
     ]
    }
   ],
   "source": [
    "#Can test on all test_images\n",
    "#Since we loaded 8k descriptions already in a dict by parsing flickr8k.token.txt , we can crosscheck with that dict\n",
    "\"\"\"\n",
    "for each imgname in flickr8kTestFolder:\n",
    "  description = python test.py -- image=imgname\n",
    "  realDescription = tokenDict[imgname]\n",
    "Based on this calculate accuracy of the model\n",
    "\"\"\"\n",
    "!python test.py --image='Me.JPG'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "unvYtcM-LQRZ"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "ImageCaptionGenerator.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "01548bdd5b884132815ed2263a312f23": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1deb5a9efc0343dcaca96b3275470d46",
      "placeholder": "​",
      "style": "IPY_MODEL_5e234d1f296a447693a7f7cfdf938192",
      "value": " 0/? [00:00&lt;?, ?it/s]"
     }
    },
    "0296430fd2224a258ae7e550687aaf1c": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_db9fc082740245d6930938fd096837a4",
       "IPY_MODEL_01548bdd5b884132815ed2263a312f23"
      ],
      "layout": "IPY_MODEL_dcfb63bf42274a969f583712bb1d409d"
     }
    },
    "1deb5a9efc0343dcaca96b3275470d46": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "287022c2589447a7b5e3596c206e1543": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_f88ae578796847c5b405eb7e97caf336",
       "IPY_MODEL_2fe148cf9d754f0380ceecfd74c0c749"
      ],
      "layout": "IPY_MODEL_780d89f11c6a4aafbe7e7ee8a200c2df"
     }
    },
    "2fe148cf9d754f0380ceecfd74c0c749": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ad14acec3317488797944eabcc18c304",
      "placeholder": "​",
      "style": "IPY_MODEL_ee5e4ba62e4840039a885bf2e89493b6",
      "value": " 8091/8091 [3:19:48&lt;00:00,  1.48s/it]"
     }
    },
    "5e234d1f296a447693a7f7cfdf938192": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "6eefe4533fba4f2bb18af1f1c9ae7279": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "780d89f11c6a4aafbe7e7ee8a200c2df": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9a9d6f798db146ceacb43c6ebe55a936": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ad14acec3317488797944eabcc18c304": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c86b7774dfb74db3a55e65fd6617e766": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "cd41028aa9f74ef081b0de5f62d7f69a": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "db9fc082740245d6930938fd096837a4": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c86b7774dfb74db3a55e65fd6617e766",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_cd41028aa9f74ef081b0de5f62d7f69a",
      "value": 0
     }
    },
    "dcfb63bf42274a969f583712bb1d409d": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ee5e4ba62e4840039a885bf2e89493b6": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f88ae578796847c5b405eb7e97caf336": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9a9d6f798db146ceacb43c6ebe55a936",
      "max": 8091,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_6eefe4533fba4f2bb18af1f1c9ae7279",
      "value": 8091
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
